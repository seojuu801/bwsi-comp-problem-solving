{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# The Great Doodle Detective: CNN Edition\n",
    "\n",
    "**Can you train a neural network to understand your terrible drawings?**\n",
    "\n",
    "You know that friend who draws a \"cat\" and it looks like a possessed potato? Or claims their scribble is \"obviously a bicycle\"? Well, today YOU become the detective — training a Convolutional Neural Network to decode humanity's worst artistic attempts.\n",
    "\n",
    "Using data from Google's Quick Draw dataset (millions of doodles drawn by real humans in under 20 seconds), you'll build a CNN that classifies hand-drawn doodles into categories like cat, dog, car, and house.\n",
    "\n",
    "---\n",
    "\n",
    "### What You'll Build:\n",
    "1. Load and visualize chaotic human doodles\n",
    "2. Build a CNN architecture from scratch\n",
    "3. Train your model to recognize patterns in the madness\n",
    "4. Test it on your own drawings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Loading the Doodle Data (PROVIDED)\n",
    "\n",
    "We'll generate synthetic \"doodle-like\" data for this exercise. In the real world, you'd download from [Google Quick Draw](https://quickdraw.withgoogle.com/data).\n",
    "\n",
    "Our synthetic doodles will have distinctive patterns for each class:\n",
    "- **Cat**: Triangular ear-like shapes + circular features\n",
    "- **Dog**: Floppy ear shapes + snout-like features  \n",
    "- **Car**: Rectangular body + circular wheels\n",
    "- **House**: Triangular roof + rectangular base\n",
    "\n",
    "Each doodle is 28×28 pixels (like MNIST), grayscale, with values 0-255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_doodle(category, size=28):\n",
    "    \"\"\"Generate a synthetic doodle. Returns a 28x28 numpy array.\"\"\"\n",
    "    img = np.zeros((size, size), dtype=np.float32)\n",
    "    noise = np.random.normal(0, 15, (size, size))\n",
    "    ox, oy = np.random.randint(-3, 4), np.random.randint(-3, 4)\n",
    "    \n",
    "    if category == 0:  # Cat\n",
    "        # Ears\n",
    "        for i in range(5):\n",
    "            for j in range(5-i):\n",
    "                y, x = 4+i+oy, 6+j+ox\n",
    "                if 0 <= y < size and 0 <= x < size:\n",
    "                    img[y, x] = 200 + np.random.randint(-30, 30)\n",
    "        for i in range(5):\n",
    "            for j in range(5-i):\n",
    "                y, x = 4+i+oy, 18-j+ox\n",
    "                if 0 <= y < size and 0 <= x < size:\n",
    "                    img[y, x] = 200 + np.random.randint(-30, 30)\n",
    "        # Face\n",
    "        for i in range(10):\n",
    "            for j in range(12):\n",
    "                y, x = 10+i+oy, 8+j+ox\n",
    "                if 0 <= y < size and 0 <= x < size:\n",
    "                    img[y, x] = 180 + np.random.randint(-20, 20)\n",
    "        # Whiskers\n",
    "        for j in range(6):\n",
    "            y, x = 16+oy, 2+j+ox\n",
    "            if 0 <= y < size and 0 <= x < size:\n",
    "                img[y, x] = 220\n",
    "            y, x = 16+oy, 20+j+ox\n",
    "            if 0 <= y < size and 0 <= x < size:\n",
    "                img[y, x] = 220\n",
    "                \n",
    "    elif category == 1:  # Dog\n",
    "        # Floppy ears\n",
    "        for i in range(8):\n",
    "            for j in range(4):\n",
    "                y, x = 6+i+oy, 4+j+ox\n",
    "                if 0 <= y < size and 0 <= x < size:\n",
    "                    img[y, x] = 190 + np.random.randint(-20, 20)\n",
    "        for i in range(8):\n",
    "            for j in range(4):\n",
    "                y, x = 6+i+oy, 20+j+ox\n",
    "                if 0 <= y < size and 0 <= x < size:\n",
    "                    img[y, x] = 190 + np.random.randint(-20, 20)\n",
    "        # Face\n",
    "        for i in range(10):\n",
    "            for j in range(12):\n",
    "                y, x = 8+i+oy, 8+j+ox\n",
    "                if 0 <= y < size and 0 <= x < size:\n",
    "                    img[y, x] = 170 + np.random.randint(-20, 20)\n",
    "        # Snout\n",
    "        for i in range(4):\n",
    "            for j in range(6):\n",
    "                y, x = 18+i+oy, 11+j+ox\n",
    "                if 0 <= y < size and 0 <= x < size:\n",
    "                    img[y, x] = 200 + np.random.randint(-20, 20)\n",
    "                    \n",
    "    elif category == 2:  # Car\n",
    "        # Body\n",
    "        for i in range(6):\n",
    "            for j in range(20):\n",
    "                y, x = 10+i+oy, 4+j+ox\n",
    "                if 0 <= y < size and 0 <= x < size:\n",
    "                    img[y, x] = 180 + np.random.randint(-20, 20)\n",
    "        # Top\n",
    "        for i in range(4):\n",
    "            for j in range(10):\n",
    "                y, x = 6+i+oy, 9+j+ox\n",
    "                if 0 <= y < size and 0 <= x < size:\n",
    "                    img[y, x] = 160 + np.random.randint(-20, 20)\n",
    "        # Wheels\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                y, x = 16+i+oy, 6+j+ox\n",
    "                if 0 <= y < size and 0 <= x < size:\n",
    "                    img[y, x] = 220 + np.random.randint(-20, 20)\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                y, x = 16+i+oy, 18+j+ox\n",
    "                if 0 <= y < size and 0 <= x < size:\n",
    "                    img[y, x] = 220 + np.random.randint(-20, 20)\n",
    "                    \n",
    "    elif category == 3:  # House\n",
    "        # Roof\n",
    "        for i in range(8):\n",
    "            width = 2 * (8-i)\n",
    "            start = 14 - (8-i)\n",
    "            for j in range(width):\n",
    "                y, x = 2+i+oy, start+j+ox\n",
    "                if 0 <= y < size and 0 <= x < size:\n",
    "                    img[y, x] = 200 + np.random.randint(-30, 30)\n",
    "        # Base\n",
    "        for i in range(10):\n",
    "            for j in range(14):\n",
    "                y, x = 10+i+oy, 7+j+ox\n",
    "                if 0 <= y < size and 0 <= x < size:\n",
    "                    img[y, x] = 170 + np.random.randint(-20, 20)\n",
    "        # Door\n",
    "        for i in range(6):\n",
    "            for j in range(4):\n",
    "                y, x = 14+i+oy, 12+j+ox\n",
    "                if 0 <= y < size and 0 <= x < size:\n",
    "                    img[y, x] = 100 + np.random.randint(-20, 20)\n",
    "    \n",
    "    img = img + noise\n",
    "    img = np.clip(img, 0, 255)\n",
    "    return img\n",
    "\n",
    "\n",
    "CATEGORIES = ['cat', 'dog', 'car', 'house']\n",
    "N_PER_CLASS = 500\n",
    "\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "for cat_idx, cat_name in enumerate(CATEGORIES):\n",
    "    for _ in range(N_PER_CLASS):\n",
    "        doodle = generate_doodle(cat_idx)\n",
    "        X_data.append(doodle)\n",
    "        y_data.append(cat_idx)\n",
    "\n",
    "X_data = np.array(X_data)\n",
    "y_data = np.array(y_data)\n",
    "\n",
    "shuffle_idx = np.random.permutation(len(X_data))\n",
    "X_data = X_data[shuffle_idx]\n",
    "y_data = y_data[shuffle_idx]\n",
    "\n",
    "print(f\"Generated {len(X_data)} doodles across {len(CATEGORIES)} categories\")\n",
    "print(f\"Image shape: {X_data[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "### Sample Doodles\n",
    "\n",
    "Let's see what we're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
    "fig.suptitle(\"Sample Doodles\", fontsize=14, fontweight='bold')\n",
    "\n",
    "for row, cat_idx in enumerate([0, 1, 2, 3]):\n",
    "    cat_samples = X_data[y_data == cat_idx][:5]\n",
    "    for col, sample in enumerate(cat_samples):\n",
    "        axes[row, col].imshow(sample, cmap='gray_r')\n",
    "        axes[row, col].axis('off')\n",
    "        if col == 0:\n",
    "            axes[row, col].set_title(f\"{CATEGORIES[cat_idx].upper()}\", fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "### Warm-Up Questions\n",
    "\n",
    "1. Looking at the sample doodles, which two categories do you think will be hardest for the CNN to distinguish? Why?\n",
    "\n",
    "2. What visual features seem most distinctive for each category?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "### A:\n",
    "YOUR ANSWERS HERE\n",
    "\n",
    "1. \n",
    "\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Preparing Data for PyTorch (PROVIDED)\n",
    "\n",
    "Before feeding data to a CNN, we need to:\n",
    "1. **Normalize** pixel values to [0, 1] range (helps training converge faster)\n",
    "2. **Split** into training and test sets\n",
    "3. **Convert** to PyTorch tensors\n",
    "4. **Add channel dimension** (CNNs expect shape: [batch, channels, height, width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize to [0, 1]\n",
    "X_normalized = X_data / 255.0\n",
    "\n",
    "# Train/test split (80/20)\n",
    "split_idx = int(0.8 * len(X_normalized))\n",
    "X_train, X_test = X_normalized[:split_idx], X_normalized[split_idx:]\n",
    "y_train, y_test = y_data[:split_idx], y_data[split_idx:]\n",
    "\n",
    "# Convert to tensors, add channel dim: (N, 28, 28) -> (N, 1, 28, 28)\n",
    "X_train_tensor = torch.FloatTensor(X_train).unsqueeze(1)\n",
    "X_test_tensor = torch.FloatTensor(X_test).unsqueeze(1)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Build Your CNN\n",
    "\n",
    "Now it's your turn to build the classifier.\n",
    "\n",
    "### Architecture Overview\n",
    "```\n",
    "Input: 1x28x28 (grayscale doodle)\n",
    "        |\n",
    "Conv2d(1->16, 3x3) + ReLU + MaxPool(2x2)  ->  16x13x13\n",
    "        |\n",
    "Conv2d(16->32, 3x3) + ReLU + MaxPool(2x2) ->  32x5x5\n",
    "        |\n",
    "Flatten -> 32*5*5 = 800 features\n",
    "        |\n",
    "Linear(800->64) + ReLU\n",
    "        |\n",
    "Linear(64->4)  ->  4 class logits\n",
    "```\n",
    "\n",
    "Fill in the `TODO` sections below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoodleDetective(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(DoodleDetective, self).__init__()\n",
    "        \n",
    "        # TODO: First conv layer - 1 input channel, 16 output channels, 3x3 kernel\n",
    "        self.conv1 = None  # TODO\n",
    "        \n",
    "        # TODO: Second conv layer - 16 input channels, 32 output channels, 3x3 kernel\n",
    "        self.conv2 = None  # TODO\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # TODO: First linear layer - 800 inputs (32*5*5), 64 outputs\n",
    "        self.fc1 = None  # TODO\n",
    "        \n",
    "        # TODO: Output layer - 64 inputs, num_classes outputs\n",
    "        self.fc2 = None  # TODO\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Input: (batch, 1, 28, 28)\n",
    "        \n",
    "        # TODO: First conv block - conv1 -> relu -> pool\n",
    "        x = None  # TODO\n",
    "        \n",
    "        # TODO: Second conv block - conv2 -> relu -> pool\n",
    "        x = None  # TODO\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # TODO: Fully connected layers - fc1 -> relu -> fc2\n",
    "        x = None  # TODO\n",
    "        x = None  # TODO\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "model = DoodleDetective(num_classes=4).to(device)\n",
    "print(\"Model architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Test forward pass\n",
    "dummy_input = torch.randn(1, 1, 28, 28).to(device)\n",
    "try:\n",
    "    dummy_output = model(dummy_input)\n",
    "    print(f\"\\nForward pass OK! Output shape: {dummy_output.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Training\n",
    "\n",
    "Fill in the training loop below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "print(\"Training...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # TODO: Zero gradients\n",
    "        \n",
    "        # TODO: Forward pass\n",
    "        outputs = None  # TODO\n",
    "        \n",
    "        # TODO: Compute loss\n",
    "        loss = None  # TODO\n",
    "        \n",
    "        # TODO: Backward pass\n",
    "        \n",
    "        # TODO: Update weights\n",
    "        \n",
    "        # Stats\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Loss: {epoch_loss:.4f} Acc: {epoch_acc:.2f}%\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "### Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot loss\n",
    "ax1.plot(range(1, NUM_EPOCHS+1), train_losses, 'b-o', linewidth=2, markersize=6)\n",
    "ax1.set_xlabel('Epoch', fontsize=11)\n",
    "ax1.set_ylabel('Loss', fontsize=11)\n",
    "ax1.set_title('Training Loss Over Time', fontsize=12, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot accuracy\n",
    "ax2.plot(range(1, NUM_EPOCHS+1), train_accuracies, 'g-o', linewidth=2, markersize=6)\n",
    "ax2.set_xlabel('Epoch', fontsize=11)\n",
    "ax2.set_ylabel('Accuracy (%)', fontsize=11)\n",
    "ax2.set_title('Training Accuracy Over Time', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim([0, 105])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Evaluation\n",
    "\n",
    "How well does the model perform on unseen doodles? Complete the evaluation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"Evaluate on test set. Returns accuracy and predictions.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # TODO: Forward pass\n",
    "            outputs = None  # TODO\n",
    "            \n",
    "            # TODO: Get predicted class\n",
    "            _, predicted = None  # TODO\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy, np.array(all_predictions), np.array(all_labels)\n",
    "\n",
    "\n",
    "test_accuracy, predictions, true_labels = evaluate_model(model, test_loader, device)\n",
    "\n",
    "print(\"Test Results\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"Correct: {int(test_accuracy * len(true_labels) / 100)}/{len(true_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.colorbar()\n",
    "\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, str(cm[i, j]), ha='center', va='center', \n",
    "                 color='white' if cm[i, j] > cm.max()/2 else 'black', fontsize=14)\n",
    "\n",
    "plt.xticks(range(4), CATEGORIES)\n",
    "plt.yticks(range(4), CATEGORIES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predictions, target_names=CATEGORIES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "### Evaluation Questions\n",
    "\n",
    "1. Which doodle category is easiest for the model? Which is hardest?\n",
    "\n",
    "2. Looking at the confusion matrix, which categories get mixed up the most? Does this make sense visually?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### A:\n",
    "YOUR ANSWERS HERE\n",
    "\n",
    "1. \n",
    "\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Test Your Own Doodles\n",
    "\n",
    "Let's test on some edge cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_doodle(model, doodle, device):\n",
    "    \"\"\"Predict class for a single doodle.\"\"\"\n",
    "    model.eval()\n",
    "    doodle_tensor = torch.FloatTensor(doodle / 255.0).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(doodle_tensor)\n",
    "        probs = torch.softmax(outputs, dim=1)[0]\n",
    "        pred_class = torch.argmax(probs).item()\n",
    "    \n",
    "    return CATEGORIES[pred_class], probs.cpu().numpy()\n",
    "\n",
    "\n",
    "test_cases = [\n",
    "    (\"Cat\", generate_doodle(0)),\n",
    "    (\"Dog\", generate_doodle(1)),\n",
    "    (\"Car\", generate_doodle(2)),\n",
    "    (\"House\", generate_doodle(3)),\n",
    "    (\"Random Noise\", np.random.uniform(0, 255, (28, 28))),\n",
    "    (\"Blank\", np.zeros((28, 28))),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (name, doodle) in enumerate(test_cases):\n",
    "    prediction, probs = predict_doodle(model, doodle, device)\n",
    "    confidence = max(probs) * 100\n",
    "    \n",
    "    axes[idx].imshow(doodle, cmap='gray_r')\n",
    "    axes[idx].set_title(f\"{name}\\nPredicted: {prediction} ({confidence:.1f}%)\")\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle(\"Test Cases\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "### Draw Your Own Doodle\n",
    "\n",
    "Run the `%matplotlib tk` cell first to enable interactive mode.\n",
    "\n",
    "**Instructions:**\n",
    "1. Run the canvas cell - a popup window will appear\n",
    "2. Click and drag to draw\n",
    "3. Click CLEAR to start over\n",
    "4. Click DONE when finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q0furm4hnsm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to interactive backend (required for drawing canvas)\n",
    "# If this doesn't work, try: %matplotlib qt  or  %matplotlib widget\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.widgets import Button\n",
    "\n",
    "class DoodleCanvas:\n",
    "    def __init__(self, size=28):\n",
    "        self.size = size\n",
    "        self.canvas = np.zeros((size, size))\n",
    "        self.drawing = False\n",
    "        self.last_point = None\n",
    "        \n",
    "    def draw(self):\n",
    "        self.fig, self.ax = plt.subplots(figsize=(6, 7))\n",
    "        plt.subplots_adjust(bottom=0.2)\n",
    "        \n",
    "        self.ax.set_title(\"Draw here - click DONE when finished\")\n",
    "        self.ax.set_xlim(0, self.size)\n",
    "        self.ax.set_ylim(self.size, 0)\n",
    "        self.ax.set_aspect('equal')\n",
    "        self.ax.set_xticks([])\n",
    "        self.ax.set_yticks([])\n",
    "        \n",
    "        self.img_display = self.ax.imshow(self.canvas, cmap='gray_r', \n",
    "                                           vmin=0, vmax=255,\n",
    "                                           extent=[0, self.size, self.size, 0])\n",
    "        \n",
    "        ax_done = plt.axes([0.6, 0.05, 0.25, 0.075])\n",
    "        ax_clear = plt.axes([0.15, 0.05, 0.25, 0.075])\n",
    "        \n",
    "        self.btn_done = Button(ax_done, 'DONE', color='lightgreen', hovercolor='green')\n",
    "        self.btn_clear = Button(ax_clear, 'CLEAR', color='lightsalmon', hovercolor='salmon')\n",
    "        \n",
    "        self.btn_done.on_clicked(self._on_done)\n",
    "        self.btn_clear.on_clicked(self._on_clear)\n",
    "        \n",
    "        self.fig.canvas.mpl_connect('button_press_event', self._on_press)\n",
    "        self.fig.canvas.mpl_connect('button_release_event', self._on_release)\n",
    "        self.fig.canvas.mpl_connect('motion_notify_event', self._on_move)\n",
    "        \n",
    "        plt.show(block=True)\n",
    "        return self.canvas.copy()\n",
    "    \n",
    "    def _on_done(self, event):\n",
    "        plt.close(self.fig)\n",
    "    \n",
    "    def _on_clear(self, event):\n",
    "        self.canvas = np.zeros((self.size, self.size))\n",
    "        self.img_display.set_data(self.canvas)\n",
    "        self.fig.canvas.draw()\n",
    "    \n",
    "    def _draw_point(self, x, y, brush_size=1.5):\n",
    "        for dy in range(-int(brush_size), int(brush_size) + 1):\n",
    "            for dx in range(-int(brush_size), int(brush_size) + 1):\n",
    "                px, py = int(x + dx), int(y + dy)\n",
    "                if 0 <= px < self.size and 0 <= py < self.size:\n",
    "                    dist = np.sqrt(dx**2 + dy**2)\n",
    "                    if dist <= brush_size:\n",
    "                        intensity = 255 * (1 - dist / (brush_size + 0.5))\n",
    "                        self.canvas[py, px] = max(self.canvas[py, px], intensity)\n",
    "    \n",
    "    def _draw_line(self, x0, y0, x1, y1):\n",
    "        dist = max(abs(x1 - x0), abs(y1 - y0))\n",
    "        if dist == 0:\n",
    "            self._draw_point(x0, y0)\n",
    "            return\n",
    "        for i in range(int(dist) + 1):\n",
    "            t = i / dist\n",
    "            x = x0 + t * (x1 - x0)\n",
    "            y = y0 + t * (y1 - y0)\n",
    "            self._draw_point(x, y)\n",
    "    \n",
    "    def _on_press(self, event):\n",
    "        if event.inaxes != self.ax or event.button != 1:\n",
    "            return\n",
    "        self.drawing = True\n",
    "        self.last_point = (event.xdata, event.ydata)\n",
    "        self._draw_point(event.xdata, event.ydata)\n",
    "        self.img_display.set_data(self.canvas)\n",
    "        self.fig.canvas.draw()\n",
    "    \n",
    "    def _on_release(self, event):\n",
    "        self.drawing = False\n",
    "        self.last_point = None\n",
    "    \n",
    "    def _on_move(self, event):\n",
    "        if not self.drawing or event.inaxes != self.ax:\n",
    "            return\n",
    "        if self.last_point is not None and event.xdata is not None:\n",
    "            self._draw_line(self.last_point[0], self.last_point[1], \n",
    "                           event.xdata, event.ydata)\n",
    "            self.last_point = (event.xdata, event.ydata)\n",
    "            self.img_display.set_data(self.canvas)\n",
    "            self.fig.canvas.draw()\n",
    "\n",
    "\n",
    "canvas = DoodleCanvas(size=28)\n",
    "user_doodle = canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, probs = predict_doodle(model, user_doodle, device)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax1.imshow(user_doodle, cmap='gray_r')\n",
    "ax1.set_title(\"Your Doodle\")\n",
    "ax1.axis('off')\n",
    "\n",
    "colors = ['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4']\n",
    "bars = ax2.bar(CATEGORIES, probs * 100, color=colors)\n",
    "ax2.set_ylabel('Confidence (%)')\n",
    "ax2.set_title(f\"Prediction: {prediction.upper()}\")\n",
    "ax2.set_ylim([0, 100])\n",
    "\n",
    "max_idx = np.argmax(probs)\n",
    "bars[max_idx].set_edgecolor('gold')\n",
    "bars[max_idx].set_linewidth(3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Predicted: {prediction} ({probs[max_idx]*100:.1f}% confidence)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Final Questions\n",
    "\n",
    "1. What happens if someone draws something ambiguous (like a \"catdog\")? How might the model handle this?\n",
    "\n",
    "2. What's one real-world application where a doodle classifier could be useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "### A:\n",
    "YOUR ANSWERS HERE\n",
    "\n",
    "1. \n",
    "\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "CNNs learn visual patterns hierarchically - edges and shapes in early layers, complex combinations in deeper layers. By sliding filters across images, they can recognize objects regardless of position, making them powerful for visual recognition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
